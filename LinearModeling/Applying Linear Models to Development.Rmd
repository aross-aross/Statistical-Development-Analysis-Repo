---
title: "Applying Linear Models to Development with Adjusted Intercepts"
author: "Anders Vargas"
date: "9/16/2020"
output:
  md_document:
    variant: gfm
---

```{r setup, message=FALSE}
library(data.table)
library(ggplot2)
library(ggResidpanel)
```

Our Regular Flow dataframe encompasses all the changes done against tickets, including the time it takes for them to move between swimlanes  
```{r getdata}
RegularFlow <- fread("RegularFlow.csv")
```

Since our research question only concerns development, we will use a list given to use by a product owners of assignees we know are developers.
```{r prepare data}
#only grab devs
developers <- c('Alden Sharp','Alexander Strauss', 'Asha Jainand', 'Carson Ferraro', 'Jon Schipani', 'Jose Jarquin', 'Juan Altamonte', 'Pamela Bulu', 'Pedro Ortiz Rodriguez', 'Thapani Saweangsri', 'Vimal Kumar Sekar', 'Walker Carr')

RegularFlow <- RegularFlow[author.displayName %in% developers]
#filter onn developer list

# only pick up stories moving into in Progress, need to divide by 24 to get days, aggregate on ticket and other information
development_hours <- RegularFlow[fromString == "In Progress"][, .(reported_dev = sum(diff_hours)/24), by = .(sprint_name, storypoints, current_issue_type, author.displayName, component, issues.key)]
```


Looking at the density plots can help us see whether we are fulfilling the asumptions for normality.
```{r density original}
ggplot(development_hours, aes(x = reported_dev, fill =  as.factor(storypoints))) +
  geom_density(position = "stack") + ggtitle("Distribution of Reported Development by Storypoints (Stacked)")

```


With the transformation, we can see the 'corrected' distribution of reported development, although it's not entirely normal.
```{r density transformed}

ggplot(development_hours, aes(x = log10(reported_dev), fill =  as.factor(storypoints))) +
  geom_density(position = "stack") + ggtitle("Distribution of Reported Development by Storypoints (Stacked and Log Transform)")

```

We can fit the lm model visually 
```{r scatterplots by dev}
ggplot(development_hours, aes(y=reported_dev, x = as.numeric(storypoints), color = storypoints)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  facet_wrap(author.displayName~.) + ggtitle("Fitted Linear Models by Developer")
```


There are alot of outliers which don't seem realistic for this dataset (like 50 days in development), so we'll see how many issues have reported development over 15 days
```{r outliers}
nrow(development_hours[ reported_dev >= 15]) # tickets which stay in progress for more than 15 days will not be considered
```



53 of the observations have days in which they are in progress for more than 15 days, which seem very unlikely for the question we're asking. We will omit these from the dataset for now.

```{r treshold}

treshold <- 15

development_hours <- development_hours[ reported_dev <= treshold]

cat("This dataframe has", nrow(development_hours), "observations with ticket which stayed in progress for more than", treshold, "days removed.")
```

With the outliers removed, we see a bimodal distribution emerge from our storypoints, which is surprising since we see it across all the storypoint categories
```{r message=FALSE, warning=FALSE}
ggplot(development_hours, aes(x = log10(reported_dev), fill =  as.factor(storypoints))) +
  geom_density(position = "stack") + ggtitle("Distribution of Reported Development by Storypoints (Stacked and Log Transform)")
```


```{r stacked density by developer, message=FALSE, warning=FALSE}
ggplot(development_hours, aes(x = log10(reported_dev), fill =  as.factor(storypoints))) +
  geom_density(position = "stack") + ggtitle("Distribution of Reported Development by Storypoints (Stacked and Log Transform)") + facet_wrap(author.displayName~.)
```

Across all the developers in our list, we see that some developers are more consistent in terms of the distribution of how they point than others.

If we visualize the transformation applied unto the scatterplots, we can glean that it helps in terms of having more points lie on the line. 
```{r scatterplot transformations, message=FALSE, warning=FALSE}
ggplot(development_hours, aes(y=reported_dev, x = as.numeric(storypoints), color = storypoints)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  facet_wrap(author.displayName~.) + ggtitle("Fitted Linear Models by Developer")
```

We need to be able to combine the results from our model so we can interpret it. We'll create a few functions to do this: 

1) Subset data based on the value we want to subset on (author in this case)
2) Function to fit the model
3) Get metadata
4) Produce table

```{r, subset data modeling functions}

# create a function to get list of dataframes by developer 
get_subsets_data <- function(data, value, column_name) {
  data <- as.data.table(data)
  data[get(column_name) == value]
  
}
# may need to be modified 


# apply function to list of developers
developer_dataframe_profiles <- lapply(developers, get_subsets_data, data = development_hours, column_name = 'author.displayName')

# create an lm function with error handling

fit_lms <- function(developer_profiles, formula){
  
  #get the summary with the formula, formula is hardcoded here!
  summary(tryCatch(lm(formula, offset = rep(1, length(storypoints)), data = developer_profiles), error = function(e) NULL )) # fit the model
  # need to look into forcing intercept
  
}

#need to add developers to summary


# now we apply the linear model to each of the dataframes to return a list of lms
developer_lms <- lapply(developer_dataframe_profiles, fit_lms, formula = log10(reported_dev) ~ storypoints)


extract_metadata <- function(lm_summary){
    
  coeffs <- lm_summary$coefficients
  
  r_squared <- lm_summary$r.squared
  
  adjusted_rsquared <- lm_summary$adj.r.squared
  
  ftest <- pf(lm_summary$fstatistic[1], lm_summary$fstatistic[2], lm_summary$fstatistic[3], lower.tail = FALSE)
  
  model_metadata <- as.data.table( cbind(coeffs, r_squared, adjusted_rsquared, ftest))
  
  model_metadata
}

```

The rest of the functions are dedicated to naming the columns and make them readable.
``` {r, cleaning up table}
metadata_list <- lapply(developer_lms, function(X){
  
tryCatch(extract_metadata(X), error = function(e) NULL )
  
})

metadata_list_named <- Map(cbind, metadata_list, developers)

metadata_list_named <- lapply(metadata_list_named, as.data.table)

metadata_list_filtered <- Filter(function(x) length(x) > 1, metadata_list_named)



metadata_table <- rbindlist(metadata_list_filtered)

tags_intercept <- as.data.frame( rep(c('intercept', 'storypoints'), nrow(metadata_table)/2 ))

metadata_table <- cbind(metadata_table, tags_intercept)


setnames(metadata_table, "V2", "developer")

setnames(metadata_table,'rep(c("intercept", "storypoints"), nrow(metadata_table)/2)', 'tags')

setnames(metadata_table,'Pr(>|t|)', "p_value")


#need to convert back from log
metadata_table[, estimate_original := 1/log(Estimate)]

metadata_table[tags == 'intercept'][order(estimate_original)]

metadata_table[ftest <= 0.10 & tags == 'storypoints'][order(estimate_original)]

```

Since we need to be able to apply this function to different sets of data, not just developers, we'll create a uniform function, get_lm_metadata, so that an end_user can use this to explore other dimensions.
```{r, general function}


get_lm_metadata <- function(data, filter_vector, column_name_target, lm_formula) {
  
data_profiles <- lapply(filter_vector, get_subsets_data, data = development_hours, column_name = column_name_target)

lm_profiles <- lapply(data_profiles, fit_lms, formula = lm_formula)

metadata_list <- lapply(lm_profiles, function(X){
  
tryCatch(extract_metadata(X), error = function(e) NULL )
  
})
  


metadata_list_named <- Map(cbind, metadata_list, filter_vector)


metadata_list_named <- lapply(metadata_list_named, as.data.table)

metadata_list_filtered <- Filter(function(x) length(x) > 1, metadata_list_named)



metadata_table <- rbindlist(metadata_list_filtered)

tags_intercept <- as.data.frame( rep(c('intercept', 'storypoints'), nrow(metadata_table)/2 ))

metadata_table <- cbind(metadata_table, tags_intercept)


setnames(metadata_table, "V2", column_name_target)

setnames(metadata_table,'rep(c("intercept", "storypoints"), nrow(metadata_table)/2)', 'tags')

setnames(metadata_table,'Pr(>|t|)', "p_value")


#need to convert back from log
metadata_table[, estimate_original_units := 10*(Estimate)]

as.data.table(metadata_table)
# enable flexibility to get unstraformed estimate
# some column names are not making sense
#metadata_table[ftest <= 0.10 & tags == 'storypoints'][order(estimate_original)]

}
```


Now we can use the general function to pull all of our metadata. As a reminder: Our entire model is significant only if the ftest is lower than our alpha value, so we need to filter on below Î± to see the signicant models for our profiles of data. To use this function, we would just need to source the function from the file again to use it again.
```{r, unified function}

# same metadata as before, but now we can just call our list of devs and the target column to get our metadata 
developer_profiles <- get_lm_metadata(development_hours, developers, 'author.displayName', lm_formula =  log10(reported_dev) ~ storypoints)

developer_profiles[tags == 'storypoints'][ftest <= 0.10]


components <- c('Faculty / Staff Pod', 'myBullsPath', 'Offshore', 'Platform', 'ReturntoCampus', 'Student Value')

# now we can do the same for components


team_profiles <- get_lm_metadata(development_hours, components, 'component', lm_formula =  log10(reported_dev) ~ storypoints)

team_profiles[tags == 'storypoints'][ftest <= 0.10]

```

One last step: We'll use the resid panel function to examine whether the assumptions of the model are being violated. It looks like the log transformation does make sense for correcting some heteroscedacity.

```{r}


get_model <- function(developer_profiles, formula){
  
    tryCatch(lm(formula, offset = rep(1, length(storypoints)), data = developer_profiles), error = function(e) NULL ) # fit the model

  
}

developer_lms_log <- lapply(developer_dataframe_profiles, get_model, formula = log10(reported_dev) ~ storypoints)


developer_lms_originalunits <- lapply(developer_dataframe_profiles, get_model, formula = reported_dev ~ storypoints)

developer_lms_log

developer_lms_originalunits

```


``` {r}
resid_panel(developer_lms_log[[1]])

resid_panel(developer_lms_log[[2]])

resid_panel(developer_lms_log[[4]])

resid_panel(developer_lms_log[[5]])

resid_panel(developer_lms_log[[6]])

resid_panel(developer_lms_log[[8]])

resid_panel(developer_lms_log[[9]])

resid_panel(developer_lms_log[[11]])

resid_panel(developer_lms_log[[12]])

```

```{r}
resid_panel(developer_lms_originalunits[[1]])

resid_panel(developer_lms_originalunits[[2]])

resid_panel(developer_lms_originalunits[[4]])

resid_panel(developer_lms_originalunits[[5]])

resid_panel(developer_lms_originalunits[[6]])

resid_panel(developer_lms_originalunits[[8]])

resid_panel(developer_lms_originalunits[[9]])

resid_panel(developer_lms_originalunits[[11]])

resid_panel(developer_lms_originalunits[[12]])
```



