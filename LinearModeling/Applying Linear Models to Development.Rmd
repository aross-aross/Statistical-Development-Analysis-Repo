---
title: "Applying Linear Models to Development with Adjusted Intercepts"
author: "Anders Vargas"
date: "9/16/2020"
output: html_document
---

```{r setup}
library(data.table)
library(ggplot2)
```


```{r getdata}
RegularFlow <- fread("RegularFlow.csv")

#only grab devs
developers <- c('Alden Sharp','Alexander Strauss', 'Asha Jainand', 'Carson Ferraro', 'Jon Schipani', 'Jose Jarquin', 'Juan Altamonte', 'Pamela Bulu', 'Pedro Ortiz Rodriguez', 'Thapani Saweangsri', 'Vimal Kumar Sekar', 'Walker Carr')

RegularFlow <- RegularFlow[author.displayName %in% developers]
#filter onn developer list

# only pick up stories moving into in Progress
development_hours <- RegularFlow[fromString == "In Progress"][, .(reported_dev = sum(diff_hours)/24), by = .(sprint_name, storypoints, current_issue_type, author.displayName, component, issues.key)]
```

We'll grab z-scores and see how our distribution is looking 

```{r}
plot(density(na.omit(development_hours$reported_dev)))
```

Since there is skewness, we will transform the y variable to correct for it. 

```{r}
plot(density(na.omit(log10(development_hours$reported_dev))))


```

```{r}
ggplot(development_hours, aes(y=reported_dev, x = as.numeric(storypoints), color = storypoints)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  facet_wrap(author.displayName~.) + ggtitle("Fitted Linear Models by Developer")
```


There is a bimodal distribution in the hours reported. Now let's check the distrubution without the large outliers

```{r}
development_hours[, zscore := scale(reported_dev)]# use scale to get zscores

development_hours[ reported_dev <= 15] # tickets which stay in progress for more than 15 days will not be considered
```




Some of the observations have days in which they are in progress, which seem very unlikely for the problem we're trying to model. We will omit these from the dataset for now.

```{r}

treshold <- 15

development_hours <- development_hours[ reported_dev <= treshold]

cat("This dataframe has", nrow(development_hours), "observations with ticket which stayed in progress for more than", treshold, "days removed.")
```

```{r}
ggplot(development_hours, aes(y=reported_dev, x = as.numeric(storypoints), color = storypoints)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  facet_wrap(author.displayName~.) + ggtitle("Fitted Linear Models by Developer")
```




```{r}
ggplot(development_hours, aes(y=log10(reported_dev), x = as.numeric(storypoints), color = storypoints)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  facet_wrap(author.displayName~.) + ggtitle("Fitted Linear Models by Developer Transformation")
```


```{r, subset data modeling functions}

# create a function to get list of dataframes by developer 
get_subsets_data <- function(data, value, column_name) {
  data <- as.data.table(data)
  data[get(column_name) == value]
  
}


# apply function to list of developers
developer_dataframe_profiles <- lapply(developers, get_subsets_data, data = development_hours, column_name = 'author.displayName')

# create an lm function with error handling

fit_lms <- function(developer_profiles, formula){
  
  #get the summary with the formula, formula is hardcoded here!
  summary(tryCatch(lm(formula, offset = rep(1, length(storypoints)), data = developer_profiles), error = function(e) NULL )) # fit the model
  # need to look into forcing intercept
  
}

#need to add developers to summary


# now we apply the linear model to each of the dataframes to return a list of lms
developer_lms <- lapply(developer_dataframe_profiles, fit_lms, formula = log10(reported_dev) ~ storypoints)


extract_metadata <- function(lm_summary){
    
  coeffs <- lm_summary$coefficients
  
  r_squared <- lm_summary$r.squared
  
  adjusted_rsquared <- lm_summary$adj.r.squared
  
  ftest <- pf(lm_summary$fstatistic[1], lm_summary$fstatistic[2], lm_summary$fstatistic[3], lower.tail = FALSE)
  
  model_metadata <- as.data.table( cbind(coeffs, r_squared, adjusted_rsquared, ftest))
  
  model_metadata
}

```


``` {r, cleaning up table}
metadata_list <- lapply(developer_lms, function(X){
  
tryCatch(extract_metadata(X), error = function(e) NULL )
  
})

metadata_list_named <- Map(cbind, metadata_list, developers)

metadata_list_named <- lapply(metadata_list_named, as.data.table)

metadata_list_filtered <- Filter(function(x) length(x) > 1, metadata_list_named)



metadata_table <- rbindlist(metadata_list_filtered)

tags_intercept <- as.data.frame( rep(c('intercept', 'storypoints'), nrow(metadata_table)/2 ))

metadata_table <- cbind(metadata_table, tags_intercept)


setnames(metadata_table, "V2", "developer")

setnames(metadata_table,'rep(c("intercept", "storypoints"), nrow(metadata_table)/2)', 'tags')

setnames(metadata_table,'Pr(>|t|)', "p_value")


#need to convert back from log
metadata_table[, estimate_original := 1/log(Estimate)]

metadata_table[tags == 'intercept'][order(estimate_original)]

metadata_table[ftest <= 0.10 & tags == 'storypoints'][order(estimate_original)]

```


```{r, general function}


get_lm_metadata <- function(data, filter_vector, column_name_target, lm_formula) {
  
data_profiles <- lapply(filter_vector, get_subsets_data, data = development_hours, column_name = column_name_target)

lm_profiles <- lapply(data_profiles, fit_lms, formula = lm_formula)

metadata_list <- lapply(lm_profiles, function(X){
  
tryCatch(extract_metadata(X), error = function(e) NULL )
  
})
  


metadata_list_named <- Map(cbind, metadata_list, filter_vector)


metadata_list_named <- lapply(metadata_list_named, as.data.table)

metadata_list_filtered <- Filter(function(x) length(x) > 1, metadata_list_named)



metadata_table <- rbindlist(metadata_list_filtered)

tags_intercept <- as.data.frame( rep(c('intercept', 'storypoints'), nrow(metadata_table)/2 ))

metadata_table <- cbind(metadata_table, tags_intercept)


setnames(metadata_table, "V2", column_name_target)

setnames(metadata_table,'rep(c("intercept", "storypoints"), nrow(metadata_table)/2)', 'tags')

setnames(metadata_table,'Pr(>|t|)', "p_value")


#need to convert back from log
metadata_table[, estimate_original := 10*(Estimate)]

as.data.table(metadata_table)
# enable flexibility to get unstraformed estimate
# some column names are not making sense
#metadata_table[ftest <= 0.10 & tags == 'storypoints'][order(estimate_original)]

}
```


Now we can use the general function to pull all of our metadata
```{r, unified function}

# same metadata as before, but now we can just call our list of devs and the target column to get our metadata 
developer_profiles <- get_lm_metadata(development_hours, developers, 'author.displayName', lm_formula =  log10(reported_dev) ~ storypoints)

developer_profiles[tags == 'storypoints'][ftest <= 0.10]


components <- c('Faculty / Staff Pod', 'myBullsPath', 'Offshore', 'Platform', 'ReturntoCampus', 'Student Value')

# now we can do the same for components


team_profiles <- get_lm_metadata(development_hours, components, 'component', lm_formula =  log10(reported_dev) ~ storypoints)

team_profiles[tags == 'storypoints'][ftest <= 0.10]

```



